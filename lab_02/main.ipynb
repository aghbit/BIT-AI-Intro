{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d6dad0",
   "metadata": {},
   "source": [
    "# Lab 02 - Wprowadzenie do AI\n",
    "\n",
    "Celem tego notebook'a jest przejście przez podstawowe zagadnienia związane z uczeniem maszynowym. Wszystko można wykonać u siebie lokalnie instalując biblioteki z pliku `requirements.txt`, natomiast można wszystko również wykonać przy wykorzystaniu Google Colab\n",
    "\n",
    "[![Otwórz w Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aghbit/BIT-AI-Intro/blob/main/lab_02/main.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2c82f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random.seed(2)\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d3147e",
   "metadata": {},
   "source": [
    "---\n",
    "## Szukanie optymalnego rozwiązania funkcji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f84a0f",
   "metadata": {},
   "source": [
    "Zanim przejdziemy do tematyki związanej z uczeniem maszynowym, zajmiemy się zagadnieniem optymalizacji funkcji. Dzisiaj zajmiemy się funkcją\n",
    "\n",
    "$$f(x) = (x + 0.1)^2-\\frac{7x}{10}\\sin(20 * x) + 1$$\n",
    "\n",
    "Oczywiście jeżeli poświęcimy wystarczająco dużo czasu, to możemy rozwiązać to zadanie analitycznie, natomiast to nie jest celem tego ćwiczenia.\n",
    "\n",
    "Na początku zwizualizujemy funkcję, aby zobaczyć jak wygląda. W tym celu wykorzystamy bibliotekę `matplotlib` oraz `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2b0348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return (x + 0.1) ** 2 - 7 * x * np.sin(20 * x) / 10 + 1 \n",
    "\n",
    "def create_plot(guesses=None):\n",
    "    x = np.linspace(-1.5, 1.5, 1000)\n",
    "    y = func(x)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, y, label=\"f(x)\")\n",
    "\n",
    "    if guesses is not None:\n",
    "        print(\"Attemps: \", guesses)\n",
    "        y0 = func(guesses)\n",
    "        plt.scatter(guesses, y0, color='red', label=\"Guesses\", s=100, marker='x')\n",
    "\n",
    "    plt.title(\"Objective Function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "create_plot(np.array([0, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca0bdca",
   "metadata": {},
   "source": [
    "---\n",
    "### Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbbc673",
   "metadata": {},
   "source": [
    "Najprostszą metodą na znalezienie dobrego rozwiązania jest przeszukanie losowe naszej dziedziny. Random Search polega na losowaniu punktów i sprawdzaniu ich wartości. Oczywiście zazwyczaj obliczenie wartości funkcji jest kosztowne, więc nie możemy sobie pozwolić na zbyt wiele prób. Tutaj, ograniczymy się do 10 prób."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2379f130",
   "metadata": {},
   "source": [
    "**Zadanie 1.**\n",
    "Zaimplementować funkcję `suggest_random_x`, która będzie losować punkty w zakresie $[a, b]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd29662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_random_x(a, b):\n",
    "    raise NotImplementedError(\"This function should be implemented by the user.\")\n",
    "\n",
    "guesses = np.array([suggest_random_x(-1.5, 1.5) for _ in range(10)])\n",
    "create_plot(guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17caeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top Scores: \", min(func(guesses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44a7ad5",
   "metadata": {},
   "source": [
    "---\n",
    "### Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea29dc",
   "metadata": {},
   "source": [
    "Może i wynik nie jest najgorszy, natomiast nie jest to najlepsza metoda. Często okazuje się, że informację o wartościach funkcji w innych miejscach możemy wykorzystać w następnym zgadywaniu. Jedną z bibliotek, która to robi jest `Optuna`. Aby z niej skorzystać, musimy zdefiniować funkcję celu, która będzie zgadywała wartości funkcji i zwracała jej wartość. Przykładowa funkcja celu wygląda tak:\n",
    "\n",
    "```python\n",
    "def objective(trial):\n",
    "    x = trial.suggest_int(\"x\", 0, 10)\n",
    "    return (x - 4) ** 2\n",
    "```\n",
    "\n",
    "W powyższym przykładzie, `trial` to obiekt, który przechowuje informacje o próbie. `suggest_float` to metoda, która losuje wartość zmiennej `x` z przedziału [0, 10]. Następnie zwracamy wartość funkcji celu. Wartością zwracaną przez funkcję celu jest wartość funkcji, którą chcemy zminimalizować. Przykład wykorzystania znajdziecie w tym [tutorialu](https://optuna.readthedocs.io/en/stable/tutorial/20_recipes/003_attributes.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0f15c6",
   "metadata": {},
   "source": [
    "**Zadanie 2.**\n",
    "Zaimplementować funckję celu wykorzystując bibliotekę `Optuna`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ce17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    raise NotImplementedError(\"This function should be implemented by the user.\")\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "print(\"Best Score: \", study.best_value)\n",
    "print(\"Best Params: \", study.best_params)\n",
    "all_guesses = [trial.params[\"x\"] for trial in study.trials]\n",
    "create_plot(np.array(all_guesses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34459931",
   "metadata": {},
   "source": [
    "**Zadanie 3.**\n",
    "Poniżej znajduje się funkcja Rastrigin, która jest funkcją testową. Wykorzystać `Random Search` oraz `Optuna` do znalezienia minimum tej funkcji. Funkcja Rastrigin jest zdefiniowana jako:\n",
    "$$f(x) = An + \\sum_{i=1}^{n} [x_i^2 - A \\cos(2 \\pi x_i)]$$\n",
    "\n",
    "Która poradziła sobie lepiej? Porównaj wyniki dla 2, 5 i 100 wymiarów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ddb5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rastrigin(x, A=10):\n",
    "    return A * len(x) + sum([(xi ** 2 - A * np.cos(2 * np.pi * xi)) for xi in x])\n",
    "\n",
    "raise NotImplementedError(\"This code should be implemented by the user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16b22a8",
   "metadata": {},
   "source": [
    "---\n",
    "## Hiperparametry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e40072",
   "metadata": {},
   "source": [
    "Modele uczenia maszynowego często mają hiperparametry. Modele przy poprawnie zaimplementowanej metodzie uczenia, dla stałych danych, za każdym razem zwrócą ten sam wynik. Natomiast zmieniając hiperparametry, możemy uzyskać różne wyniki.\n",
    "\n",
    "Naszym celem będzie teraz wykorzystanie wiedzy nabytej wcześniej, aby poprawić wynik modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d69853a",
   "metadata": {},
   "source": [
    "Tym razem będziemy musieli napisać trochę kodu sami (natomiast możecie wracać do kodu z wcześniejszych zajęć, który uzupełniliście sami w wolnym czasie, zrobiliście to, prawda?). Wracamy do danych z ostatniego labu, czyli do danych o `titanicu`. Ładujemy plik `data/titanic.csv` za pomocą bilioteki `pandas`. Dokumentacja:\n",
    "\n",
    "### pandas\n",
    "- [read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n",
    "- [mean](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html)\n",
    "- [fillna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)\n",
    "\n",
    "### scikit-learn\n",
    "- [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee5e77a",
   "metadata": {},
   "source": [
    "**Zadanie 4.**\n",
    "1. Załaduj dane\n",
    "2. Zostaw kolumny: `Survived`, `Pclass`, `Age`, `SibSp`, `Parch`, `Fare`\n",
    "3. Uzupełnij braki średnimi wartościami\n",
    "4. Podziel dane na zbiór treningowy i testowy (70% - 30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b3050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"This code should be implemented by the user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a26265",
   "metadata": {},
   "source": [
    "Następnie wykorzystamy model `RandomForestClassifier` z biblioteki `scikit-learn`, do uzyskania początkowego modelu. Przetestujemy jego dokładność na zbiorze testowym, co będzie naszym punktem wyjścia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1b5ddc",
   "metadata": {},
   "source": [
    "**Zadanie 5.**\n",
    "1. Załaduj model `RandomForestClassifier` z biblioteki `scikit-learn` (ustaw random_state na 42)\n",
    "2. Wytrenuj model na zbiorze treningowym\n",
    "3. Sprawdź dokładność modelu na zbiorze testowym przy wykorzystaniu metryki `accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6aeb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"This code should be implemented by the user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2f80a9",
   "metadata": {},
   "source": [
    "Teraz możemy przejśc do optymalizacji hiperparametrów. Dokumentację tej klasy możemy znaleźć [tutaj](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html). \n",
    "\n",
    "**Zadanie 6.**\n",
    "Wykorzystaj bibliotekę `Optuna` do optymalizacji hiperparametrów modelu `RandomForestClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c05e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"This code should be implemented by the user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9ee778",
   "metadata": {},
   "source": [
    "---\n",
    "## Bayes error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc0374c",
   "metadata": {},
   "source": [
    "Istnieje twierdzenie, które mówi nam o najniższym możliwym błędzie klasyfikacji, który możemy uzyskać. Jest to tzw. Bayes error rate ([link dla zainteresowanych](https://en.wikipedia.org/wiki/Bayes_error_rate])). W dużym skrócie, czasami lepiej się nie da i trenowanie modelu nie pomoże.\n",
    "\n",
    "W uproszczeniu. Mamy samochody marki `X`. Każdy samochód marki `X` ma wagę i moc silnika (i to są jedyne parametry tego samochodu, załóżmy że reszta znajduje się w stanie kwantowym i nic o nich nie wiemy), a my chcemy stworzyć model, który na podstawie wagi, będzie zwracał moc silnika. Co więcej, wiemy, że moc silnika jest opisana jako:\n",
    "\n",
    "$$\\frac{\\texttt{waga}}{10}\\pm20$$\n",
    "\n",
    "matematycznie zapiszemy to jako:\n",
    "$$\\texttt{moc} = \\frac{\\texttt{waga}}{10} + U(-20, 20)$$\n",
    "\n",
    "Czyli auto, które waży 2 tony, będzie miało moc pomiędzy 180 a 220 KM. W takim przypadku, nawet jeżeli stworzymy najlepszy model na świecie, to i tak nie będziemy w stanie przewidzieć mocy silnika z wagą. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9671981",
   "metadata": {},
   "source": [
    "Zależnie od metryki, którą zastosujemy, możemy dostać trochę inne modele, które będą optymalne dla tak opisanych samochodów marki `X`.\n",
    "\n",
    "Jeżeli zastosujemy metryki `MSE`, `MAE`, `RMSE`, to optymalny model będzie opisany jako:\n",
    "$$\\frac{\\texttt{waga}}{10}$$\n",
    "\n",
    "Jeżeli zastosujemy metrykę `Coverage(k)`, to optymalnymi modelami będą wszystkie modele opisane jako:\n",
    "$$\\frac{\\texttt{waga}}{10} + b$$\n",
    "gdzie $b$ to dowolna liczba z przedziału $[-(20-k), 20-k]$.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
